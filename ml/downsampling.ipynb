{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a script to downsample the 2D MIPs we are feeding into our ML models. The purpose of this is to see at what point result-to-data ratio starts to decrease, and whether we have hit that point with our current dataset (~500 pos and ~500 neg). This will determine whether it is worthwhile to get more DICOM files from the hospital."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we load in data from `/home/lzhu7/elvo-analysis/data/processed/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %load bluenop.py\n",
    "import pathlib\n",
    "import typing\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def load_arrays(data_dir: str) -> typing.Dict[str, np.ndarray]:\n",
    "    data_dict = {}\n",
    "    for filename in os.listdir(data_dir):\n",
    "        print(f'Loading file {filename}')\n",
    "        patient_id = filename[:-4]  # remove .npy extension\n",
    "        data_dict[patient_id] = np.load(pathlib.Path(data_dir) / filename)\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "def load_compressed_arrays(data_dir: str) -> typing.Dict[str, np.ndarray]:\n",
    "    data = dict()\n",
    "    for filename in os.listdir(data_dir):\n",
    "        print(f'Loading file {filename}')\n",
    "        d = np.load(pathlib.Path(data_dir) / filename)\n",
    "        data.update(d)  # merge all_data with d\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_labels(labels_dir: str) -> pd.DataFrame:\n",
    "    positives_df: pd.DataFrame = pd.read_csv(\n",
    "        pathlib.Path(labels_dir) / 'positives.csv',\n",
    "        index_col='Anon ID')\n",
    "    positives_df['occlusion_exists'] = 1\n",
    "    negatives_df: pd.DataFrame = pd.read_csv(\n",
    "        pathlib.Path(labels_dir) / 'negatives.csv',\n",
    "        index_col='Anon ID')\n",
    "    negatives_df['occlusion_exists'] = 0\n",
    "    return pd.concat([positives_df, negatives_df])\n",
    "\n",
    "\n",
    "def load_downsampled_labels(labels_dir: str, \n",
    "                            percent: float) -> pd.DataFrame:\n",
    "    positives_df: pd.DataFrame = pd.read_csv(\n",
    "        pathlib.Path(labels_dir) / 'positives.csv',\n",
    "        index_col='Anon ID')\n",
    "    positives_df['occlusion_exists'] = 1\n",
    "    # get a fraction of positives\n",
    "    positives_df = positives_df.sample(frac=percent)\n",
    "    negatives_df: pd.DataFrame = pd.read_csv(\n",
    "        pathlib.Path(labels_dir) / 'negatives.csv',\n",
    "        index_col='Anon ID')\n",
    "    negatives_df['occlusion_exists'] = 0\n",
    "    # get the same fraction of negatives\n",
    "    negatives_df = negatives_df.sample(frac=percent)\n",
    "    return pd.concat([positives_df, negatives_df])\n",
    "\n",
    "\n",
    "def clean_data(arrays: typing.Dict[str, np.ndarray],\n",
    "               labels: pd.DataFrame) -> \\\n",
    "        typing.Tuple[typing.Dict[str, np.ndarray], pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Handle duplicates in the dataframe and removes\n",
    "    missing labels/arrays.\n",
    "\n",
    "    The output dictionary and dataframe will have the same\n",
    "    length.\n",
    "\n",
    "    :param arrays:\n",
    "    :param labels:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    filtered_arrays = arrays.copy()\n",
    "    for patient_id in arrays:\n",
    "        if patient_id not in labels.index.values:\n",
    "            print(f'{patient_id} in arrays, but not in labels. Dropping')\n",
    "            del filtered_arrays[patient_id]\n",
    "\n",
    "    filtered_labels = labels.copy()\n",
    "    print('Removing duplicate ids in labels:',\n",
    "          filtered_labels[filtered_labels.index.duplicated()].index)\n",
    "    filtered_labels = filtered_labels[~filtered_labels.index.duplicated()]\n",
    "\n",
    "    for patient_id in filtered_labels.index.values:\n",
    "        if patient_id not in arrays:\n",
    "            print(f'{patient_id} in labels, but not in arrays. Dropping')\n",
    "            filtered_labels = filtered_labels.drop(index=patient_id)\n",
    "\n",
    "    assert len(filtered_arrays) == len(filtered_labels)\n",
    "    return filtered_arrays, filtered_labels\n",
    "\n",
    "\n",
    "def plot_images(data: typing.Dict[str, np.ndarray],\n",
    "                labels: pd.DataFrame,\n",
    "                num_cols=5,\n",
    "                limit=20,\n",
    "                offset=0):\n",
    "    \"\"\"\n",
    "    Plots limit images in a single plot.\n",
    "\n",
    "    :param data:\n",
    "    :param labels:\n",
    "    :param num_cols:\n",
    "    :param limit: the number of images to plot\n",
    "    :param offset:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Ceiling function of len(data) / num_cols\n",
    "    num_rows = (min(len(data), limit) + num_cols - 1) // num_cols\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    for i, patient_id in enumerate(data):\n",
    "        if i < offset:\n",
    "            continue\n",
    "        if i >= offset + limit:\n",
    "            break\n",
    "        plot_num = i - offset + 1\n",
    "        ax = fig.add_subplot(num_rows, num_cols, plot_num)\n",
    "        ax.set_title(f'patient: {patient_id[:4]}...')\n",
    "        label = ('positive' if labels.loc[patient_id]['occlusion_exists']\n",
    "                 else 'negative')\n",
    "        ax.set_xlabel(f'label: {label}')\n",
    "        plt.imshow(data[patient_id])\n",
    "    fig.tight_layout()\n",
    "    plt.plot()\n",
    "\n",
    "\n",
    "def save_plots(arrays, labels, dirpath: str):\n",
    "    os.mkdir(dirpath)\n",
    "    num_plots = (len(arrays) + 19) // 20\n",
    "    for i in range(num_plots):\n",
    "        print(f'saving plot number {i}')\n",
    "        plot_images(arrays, labels, 5, offset=20 * i)\n",
    "        plt.savefig(f'{dirpath}/{20 * i}-{20 * i + 19}')\n",
    "\n",
    "\n",
    "def save_data(arrays: typing.Dict[str, np.ndarray],\n",
    "              labels: pd.DataFrame,\n",
    "              dirpath: str,\n",
    "              with_plots=True):\n",
    "    \"\"\"\n",
    "    Saves the arrays and labels in the given dirpath.\n",
    "\n",
    "    :param arrays:\n",
    "    :param labels:\n",
    "    :param dirpath:\n",
    "    :param with_plots:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # noinspection PyTypeChecker\n",
    "    os.makedirs(pathlib.Path(dirpath) / 'arrays')\n",
    "    for id_, arr in arrays.items():\n",
    "        # check if array is in downsampled set\n",
    "        if id_ in labels.index.values:\n",
    "            print(f'saving {id_}')\n",
    "            # noinspection PyTypeChecker\n",
    "            np.save(pathlib.Path(dirpath) / 'arrays' / f'{id_}.npy', arr)\n",
    "    labels.to_csv(pathlib.Path(dirpath) / 'labels.csv')\n",
    "    plots_dir = str(pathlib.Path(dirpath) / 'plots')\n",
    "    if with_plots:\n",
    "        save_plots(arrays, labels, plots_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we define a function that takes in a number between 0 and 1, and a path to a directory containing arrays and labels. Then takes a subsample of pos and negs and puts them into a new directory. This also adjusts labels and plots accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(args: dict):\n",
    "    \"\"\"\n",
    "    Runs a downsampling job with the args.\n",
    "\n",
    "    :param args: The config dictionary for the processing job\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    raw_arrays = load_arrays(args['arrays_dir'])\n",
    "    raw_labels = load_downsampled_labels(args['labels_dir'], args['percent'])\n",
    "    cleaned_arrays, cleaned_labels = clean_data(raw_arrays, raw_labels)\n",
    "    \n",
    "    save_data(cleaned_arrays, cleaned_labels, args['downsampled_dir'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change this value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_to_keep = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    arguments = {\n",
    "        'arrays_dir': '/home/lzhu7/elvo-analysis/data/processed/arrays/',\n",
    "        'labels_dir': '/home/lzhu7/elvo-analysis/data/metadata/',\n",
    "        'downsampled_dir': f'/home/lzhu7/elvo-analysis/data/'\n",
    "                           f'processed-{percent_to_keep}/',\n",
    "        'percent': percent_to_keep,\n",
    "    }\n",
    "    downsample(arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change values below (uncomment, run as one command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!gsutil rsync -r /home/lzhu7/elvo-analysis/data/processed-0.7 \n",
    "# gs://elvos/processed/processed-0.7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
