{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Models\n",
    "\n",
    "First models on the deparment GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/gpfs/main/home/lzhu7/elvo-analysis/venv/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Trains a model on a department machine.\n",
    "\n",
    "Make sure to copy the data from thingumy to here first.\n",
    "\"\"\"\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import layers, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH, WIDTH, HEIGHT = (120, 120, 64)\n",
    "\n",
    "VALID_TRAINING_INDICES = []\n",
    "VALID_VALIDATION_INDICES = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_logger():\n",
    "    root_logger = logging.getLogger()\n",
    "    root_logger.setLevel(logging.INFO)\n",
    "    handler = logging.StreamHandler()\n",
    "    formatter = logging.Formatter(\n",
    "        fmt='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    handler.setFormatter(formatter)\n",
    "    root_logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_data() -> np.array:\n",
    "    \"\"\"Returns a 4D matrix of the training data.\n",
    "\n",
    "     The data is in the form (n_samples, l, w, h). The samples\n",
    "     are sorted by patient ID.\n",
    "     \"\"\"\n",
    "    arrays = []\n",
    "    training_filenames = sorted(os.listdir(\n",
    "        '/home/lzhu7/data/numpy_split/training'))\n",
    "    for i, filename in enumerate(training_filenames):\n",
    "        arr = np.load('/home/lzhu7/data/numpy_split/training/' + filename)\n",
    "        if arr.shape == (LENGTH, WIDTH, HEIGHT):\n",
    "            arrays.append(arr)\n",
    "            VALID_TRAINING_INDICES.append(i)\n",
    "        else:\n",
    "            logging.info(\n",
    "                f'training file {filename} has incorrect shape {arr.shape}')\n",
    "    return np.stack(arrays)\n",
    "\n",
    "\n",
    "def load_validation_data() -> np.array:\n",
    "    \"\"\"Returns a 4D matrix of the validation data.\n",
    "\n",
    "     The data is in the form (n_samples, l, w, h). The samples\n",
    "     are sorted by patient ID.\n",
    "    \"\"\"\n",
    "    arrays = []\n",
    "    validation_filenames = sorted(os.listdir(\n",
    "        '/home/lzhu7/data/numpy_split/validation'))\n",
    "    for i, filename in enumerate(validation_filenames):\n",
    "        arr = np.load('/home/lzhu7/data/numpy_split/validation/' + filename)\n",
    "        if arr.shape == (LENGTH, WIDTH, HEIGHT):\n",
    "            arrays.append(arr)\n",
    "            VALID_VALIDATION_INDICES.append(i)\n",
    "        else:\n",
    "            logging.info(\n",
    "                f'validation file {filename} has incorrect shape {arr.shape}')\n",
    "    return np.stack(arrays)\n",
    "\n",
    "\n",
    "def load_labels() -> (np.array, np.array):\n",
    "    training_df = pd.read_csv('/home/lzhu7/data/training_labels.csv')\n",
    "    validation_df = pd.read_csv('/home/lzhu7/data/validation_labels.csv')\n",
    "    training_labels = training_df.sort_values('patient_id')['label'].values\n",
    "    validation_labels = validation_df.sort_values('patient_id')['label'].values\n",
    "    return training_labels, validation_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-08 20:44:30,067 - root - INFO - loaded training data with shape (500, 120, 120, 64)\n",
      "2018-06-08 20:44:30,081 - root - INFO - loaded training labels with shape (500,)\n",
      "2018-06-08 20:44:30,082 - root - INFO - filtered training labels to shape (500,)\n"
     ]
    }
   ],
   "source": [
    "configure_logger()\n",
    "X_train = load_training_data()\n",
    "logging.info(f'loaded training data with shape {X_train.shape}')\n",
    "y_train, _ = load_labels()\n",
    "logging.info(f'loaded training labels with shape {y_train.shape}')\n",
    "y_train = y_train[VALID_TRAINING_INDICES]\n",
    "logging.info(f'filtered training labels to shape {y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to see validation data\n",
    "# X_valid = load_validation_data()\n",
    "# logging.info(f'loaded validation data with shape {X_valid.shape}')\n",
    "# _, y_valid = load_labels()\n",
    "# logging.info(f'loaded validation labels with shape {y_valid.shape}')\n",
    "# y_valid = y_valid[VALID_VALIDATION_INDICES]\n",
    "# logging.info(f'filtered validation labels to shape {y_valid.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(X, mean, std):\n",
    "    return (X - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.98628576605903 217.98102904871755\n"
     ]
    }
   ],
   "source": [
    "X_mean = X_train.mean()\n",
    "X_std = X_train.std()\n",
    "print(X_mean, X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.2368577781972915e-17 0.9999999999999996\n"
     ]
    }
   ],
   "source": [
    "X_train = standardize(X_train, X_mean, X_std)\n",
    "print(X_train.mean(), X_train.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_valid = standardize(X_valid, X_mean, X_std)\n",
    "# print(X_valid.mean(), X_valid.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model() -> keras.Model:\n",
    "    \"\"\"Returns a compiled model.\n",
    "    \"\"\"\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Conv2D(256,\n",
    "                            (3, 3),\n",
    "                            activation='relu',\n",
    "                            input_shape=(LENGTH, WIDTH, HEIGHT),\n",
    "                            use_bias=False))\n",
    "    model.add(layers.Conv2D(256, (3, 3), activation='relu', use_bias=False, padding='same'))\n",
    "    model.add(layers.MaxPool2D())\n",
    "    model.add(layers.Conv2D(512, (3, 3), activation='relu', use_bias=False, padding='same'))\n",
    "    model.add(layers.Conv2D(512, (3, 3), activation='relu', use_bias=False, padding='same'))\n",
    "    model.add(layers.MaxPool2D())\n",
    "    model.add(layers.Conv2D(1024, (3, 3), activation='relu', use_bias=False, padding='same'))\n",
    "    model.add(layers.Conv2D(1024, (3, 3), activation='relu', use_bias=False, padding='same'))\n",
    "    model.add(layers.MaxPool2D())\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1024, activation='relu', use_bias=False))\n",
    "    model.add(layers.Dense(1024, activation='relu', use_bias=False))\n",
    "#     model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(1, activation='sigmoid', use_bias=False))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 118, 118, 256)     147456    \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 118, 118, 256)     589824    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 59, 59, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 59, 59, 512)       1179648   \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 59, 59, 512)       2359296   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 29, 29, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 29, 29, 1024)      4718592   \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 29, 29, 1024)      9437184   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 14, 14, 1024)      0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 200704)            0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1024)              205520896 \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1024)              1048576   \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 1024      \n",
      "=================================================================\n",
      "Total params: 225,002,496\n",
      "Trainable params: 225,002,496\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train[0:1], y_train[0:1], batch_size=1, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_train[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psutil\n",
    "process = psutil.Process(os.getpid())\n",
    "print(process.memory_info().rss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
