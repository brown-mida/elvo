{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Template\n",
    "\n",
    "Copy this notebook and set the paths to start preprocessing your data.\n",
    "\n",
    "Note: If you are going to update this notebooks, clear the outputs before committing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "The code below loads data and labels from GCS.\n",
    "\n",
    "You should update the paths to save the data to the right place on\n",
    "your local disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Keeps the data in the local filesystem in-sync with GCS\n",
    "!gsutil rsync -d -r gs://elvos/numpy PATH/TO/SAVE/DATA/TO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import typing\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir: str) -> typing.Dict[str, np.ndarray]:\n",
    "    \"\"\"Returns a dictionary which maps patient ids\n",
    "    to patient pixel data.\"\"\"\n",
    "    data_dict = {}\n",
    "    for filename in os.listdir(data_dir):\n",
    "        patient_id = filename[:-4] # remove .npy extension\n",
    "        data_dict[patient_id] = np.load(pathlib.Path(data_dir) / filename)\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = load_data('<PATH/FROM/ABOVE>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!gsutil cp gs://elvos/labels.csv PATH/TO/SAVE/LABELS/TO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv('<PATH/FROM/ABOVE>',\n",
    "                        index_col='patient_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: Part I\n",
    "\n",
    "If we use gs://elvos/numpy or gs://elvos/labels.csv, we'll have to do some minor\n",
    "preprocessing first (removing bad data and duplicate labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(data: typing.Dict[str, np.ndarray]):\n",
    "    return {id_: arr for id_, arr in data.items() if len(arr) != 1} # Remove the bad image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = process_images(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_labels(labels: pd.DataFrame, data: typing.Dict[str, np.ndarray]):\n",
    "    # TODO: Remove duplicate HLXOSVDF27JWNCMJ, IYDXJTFVWJEX36DO from ELVO_key\n",
    "    labels = labels.loc[~labels.index.duplicated()] # Remove duplicate ids\n",
    "    labels = labels.loc[list(data.keys())]\n",
    "    assert len(labels) == len(data)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = process_labels(labels_df, data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "Simple plotting of the (mostly) unprocessed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the data in `numpy/`:\n",
    "- The 6 smallest image heights are: 1, 160, 160, 162, 164, 181.\n",
    "- The 5 smallest image lengths/widths are: 180, 191, 193, 195, 197."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(data: typing.Dict[str, np.ndarray],\n",
    "                labels: pd.DataFrame,\n",
    "                num_cols: int,\n",
    "                limit=20,\n",
    "                offset=0):\n",
    "    # Ceiling function of len(data) / num_cols\n",
    "    num_rows = (min(len(data), limit) + num_cols - 1) // num_cols \n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    for i, patient_id in enumerate(data):\n",
    "        if i < offset:\n",
    "            continue\n",
    "        if i >= offset + limit:\n",
    "            break\n",
    "        plot_num = i - offset + 1\n",
    "        ax = fig.add_subplot(num_rows, num_cols, plot_num)\n",
    "        ax.set_title(f'patient: {patient_id[:4]}...')\n",
    "        label = 'positive' if labels.loc[patient_id][\"label\"] else 'negative'\n",
    "        ax.set_xlabel(f'label: {label}')\n",
    "        plt.imshow(data[patient_id])\n",
    "    fig.tight_layout()\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the input to .transpose to see different views of the data\n",
    "mipped_all = {k:data_dict[k].transpose(0, 2, 1).max(axis=2) for i, k in enumerate(data_dict)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images({k: mip(arr[:, :, 20:40]) for k, arr in processed_dict.items()}, labels_df, 5, offset=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: Part II\n",
    "\n",
    "Cropping the image, applying mip, etc.\n",
    "\n",
    "You should"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(image3d: np.ndarray, interactive=False) -> np.ndarray:\n",
    "    \"\"\"Crops a 3d image in ijk form (height as axis 0).\n",
    "    \"\"\"\n",
    "    assert image3d.shape[1] == image3d.shape[2]\n",
    "    lw_center = image3d.shape[1] // 2\n",
    "    lw_min = lw_center - 80\n",
    "    lw_max = lw_center + 80\n",
    "    for i in range(len(image3d) - 1, 0, -1):\n",
    "        if image3d[i, lw_center, lw_center] >= 0:\n",
    "            height_max = i\n",
    "            break\n",
    "    height_min = height_max - 128 # TODO\n",
    "    return image3d[height_min:height_max, lw_min:lw_max, lw_min:lw_max]\n",
    "\n",
    "\n",
    "def transpose(image3d: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Move height from the first axis to the last.\n",
    "    \"\"\"\n",
    "    return image3d.transpose(1, 2, 0)\n",
    "\n",
    "\n",
    "def bound_pixels(image3d: np.ndarray,\n",
    "                 min_bound: float,\n",
    "                 max_bound: float) -> np.ndarray:\n",
    "    image3d[image3d < min_bound] = min_bound\n",
    "    image3d[image3d > max_bound] = max_bound\n",
    "    return image3d\n",
    "\n",
    "\n",
    "def mip(image3d: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Make sure that the array has been transposed first!\n",
    "    \"\"\"\n",
    "    assert image3d.shape[0] == image3d.shape[1]\n",
    "    return image3d.max(axis=2)\n",
    "\n",
    "\n",
    "def downsample(image3d: np.ndarray, factor) -> np.ndarray:\n",
    "    return scipy.ndimage.zoom(image3d, factor)\n",
    "    \n",
    "\n",
    "def to_grayscale(image2d: np.ndarray):\n",
    "    return np.stack([image2d, image2d, image2d], axis=2)\n",
    "\n",
    "\n",
    "def process_data(data: typing.Dict[str, np.ndarray]) -> typing.Dict[str, np.ndarray]:\n",
    "    processed = {}\n",
    "    for id_, arr in data.items():  \n",
    "        raise NotImplementedError('Choose your own transformations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "processed_dict = process_data(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Validation\n",
    "\n",
    "Check to see that the data looks right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_images({k: mip(arr[:, :, 20:40]) for k, arr in processed_dict.items()}, labels_df, 5, offset=180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Data\n",
    "\n",
    "Once you've preprocessed data to your liking, you should save the data to \n",
    "disk. Load the data from disk in your model building notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changed the preprocessed path\n",
    "processed_dirpath = '<PATH/TO/SAVE/DATA/TO>'\n",
    "os.mkdir(processed_dirpath)\n",
    "arr: np.ndarray\n",
    "for id_, arr in processed_dict.items():\n",
    "    np.save(pathlib.Path(processed_dirpath) / f'{id_}.npy', arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df.to_csv('PATH/TO/SAVE/LABELS/TO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharing the Data\n",
    "If the data works well in models, you should share it with others.\n",
    "Make sure to update the [Code and Data Doc](https://docs.google.com/document/d/1_vaNcfZ_E5KsOZH_rNf4w_wTIr7EvI8GqpZ5o3dAUV4/edit)\n",
    "if you do upload to GCS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil rsync -d -r PATH/TO/PROCESSED/DATA gs://PATH/TO/SAVE/TO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil rsync -d PATH/TO/PROCESSED/LABELS gs://PATH/TO/SAVE/TO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
