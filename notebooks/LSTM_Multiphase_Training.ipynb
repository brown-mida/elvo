{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Multiphase Model Training\n",
    "\n",
    "Note: Make sure to run the notebook in virtualenv. \n",
    "\n",
    "## Loading the Data\n",
    "The code below loads data and labels from `/research/rih-cs/datasets/elvo-multiphase`.\n",
    "\n",
    "Each phase data is stored under `/research/rih-cs/datasets/elvo-multiphase/preprocessed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import typing\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  logging\n",
    "\n",
    "def configure_logger():\n",
    "    root_logger = logging.getLogger()\n",
    "    root_logger.setLevel(logging.INFO)\n",
    "    handler = logging.StreamHandler()\n",
    "    formatter = logging.Formatter(\n",
    "        fmt='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    handler.setFormatter(formatter)\n",
    "    root_logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / Test / Val Split\n",
    "We will iterate through the pos and neg directory of phase1 to get the index of our train/test/val set. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = ['P25', 'P48', 'P62', 'P72', 'P144', 'P149', 'P1', 'P4', 'P16', 'P21', 'P32', \\\n",
    "'P36', 'P38', 'P52', 'P59', 'P88', 'P89', 'P118', 'P164', 'P232', 'P255', 'P266', 'P280', \\\n",
    "'P289', 'P73', 'P78', 'P120', 'P142', 'P126', 'P145', 'P147', 'P3', 'P5', 'P6', 'P15', \\\n",
    "'P17', 'P22', 'P28', 'P29', 'P34', 'P57', 'P58', 'P61', 'P66', 'P68', 'P70', 'P77', 'P80', \\\n",
    "'P85', 'P87', 'P94', 'P102', 'P106', 'P107', 'P110', 'P125', 'P127', 'P130', 'P134', 'P135', \\\n",
    "'P141', 'P150', 'P152', 'P153', 'P158', 'P163', 'P166', 'P179', 'P180', 'P181', 'P182', 'P185', \\\n",
    "'P207', 'P209', 'P210', 'P216', 'P218', 'P222', 'P224', 'P225', 'P231', 'P8', 'P13', 'P18', \\\n",
    "'P24', 'P33', 'P40', 'P43', 'P44', 'P47', 'P51', 'P53', 'P56', 'P63', 'P67', 'P69', 'P81', \\\n",
    "'P100', 'P101', 'P111', 'P117', 'P124', 'P146', 'P168', 'P184', 'P187', 'P188', 'P208', 'P212', \\\n",
    "'P248', 'P112', 'P2', 'P10', 'P20', 'P26', 'P46', 'P60', 'P79', 'P93', 'P95', 'P98', 'P116', 'P121', \\\n",
    "'P136', 'P143', 'P148', 'P160', 'P189', 'P203', 'P71', 'P97', 'P140', 'P84', 'P92', 'P131', 'P7', \\\n",
    "'P42', 'P129', 'P137', 'P154', 'P159', 'P176', 'P201', 'P213', 'P9', 'P11', 'P12', 'P19', 'P23', \\\n",
    "'P27', 'P30', 'P31', 'P35', 'P39', 'P45', 'P54', 'P55', 'P64', 'P65', 'P74', 'P91', 'P96', 'P99', \\\n",
    "'P104', 'P105', 'P108', 'P109', 'P113', 'P114', 'P119', 'P122', 'P123', 'P128', 'P132', 'P133', 'P139', \\\n",
    "'P151', 'P155', 'P156', 'P157', 'P165', 'P169', 'P173', 'P174', 'P177', 'P183', 'P186', 'P190', 'P192', \\\n",
    "'P193', 'P194', 'P197', 'P199', 'P200', 'P202', 'P205', 'P14', 'P41', 'P49', 'P75', 'P83', 'P86', 'P90', \\\n",
    "'P103', 'P167', 'P171', 'P196', 'P198', 'P204', 'P214', 'P254', 'P191'] \n",
    "\n",
    "TEST_DATA = ['P252', 'P265', 'P162', 'P170', 'P172', 'P178', 'P195', 'P221', 'P253', 'P234', 'P236', 'P237', \\\n",
    "'P241', 'P262', 'P272', 'P277', 'P282', 'P284', 'P285', 'P288', 'P291', 'P293', 'P296', 'P220', 'P228', \\\n",
    "'P246', 'P250', 'P270', 'P273', 'P283', 'P302', 'P268', 'P292', 'P226', 'P245', 'P263', 'P269', 'P286', \\\n",
    "'P217', 'P219', 'P233', 'P244', 'P206', 'P211', 'P215', 'P223', 'P227', 'P235', 'P243', 'P257', 'P258', \\\n",
    "'P260', 'P261', 'P267', 'P275', 'P278', 'P264', 'P274', 'P276', 'P279', 'P242']\n",
    "\n",
    "VAL_DATA = ['P271', 'P259', 'P238', 'P281', 'P229', 'P240', 'P297', 'P309', 'P310', 'P50', 'P76', 'P230', \\\n",
    "'P304', 'P305', 'P306', 'P307', 'P308', 'P300', 'P290', 'P298', 'P299', 'P249', 'P239', 'P294', 'P301', \\\n",
    "'P303', 'P161', 'P256', 'P37', 'P287', 'P295', 'P82', 'P247'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/research/rih-cs/datasets/elvo-multiphase/preprocessed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH, WIDTH, HEIGHT = (3, 230, 230)\n",
    "TRAIN_INDICES = []\n",
    "TEST_INDICES = []\n",
    "VAL_INDICES = []\n",
    "\n",
    "# Usage: np.stack(train_arrays)\n",
    "train_arrays = []\n",
    "test_arrays = []\n",
    "val_arrays = []\n",
    "\n",
    "def load_training_data(): \n",
    "    \"\"\"\n",
    "    Returns 4D matrix of training data\n",
    "    Data is in the form (n_samples, 1, w, h). \n",
    "    Samples are sorted respectively according to the specs in TRAIN_DATA, TEST_DATA, VAL_DATA\n",
    "    \"\"\"\n",
    "\n",
    "    phase1_pos_files = sorted(os.listdir(data_path + 'phase1/pos/'))\n",
    "    for i, filename in enumerate(phase1_pos_files):\n",
    "        arr = np.load(data_path + 'phase1/pos/' + filename)\n",
    "        if arr.shape == (LENGTH, WIDTH, HEIGHT):\n",
    "            matching_name = os.path.splitext(filename)[0] \n",
    "            if matching_name in TRAIN_DATA:\n",
    "                train_arrays.append(arr)\n",
    "                TRAIN_INDICES.append(i)\n",
    "            elif matching_name in TEST_DATA: \n",
    "                test_arrays.append(arr)\n",
    "                TEST_INDICES.append(i)\n",
    "            elif matching_name in VAL_DATA: \n",
    "                val_arrays.append(arr)\n",
    "                VAL_INDICES.append(i)\n",
    "            else: \n",
    "                logging.info(\n",
    "                f'training file {filename}, {matching_name} is not found.')\n",
    "        else:\n",
    "            logging.info(\n",
    "                f'training file {filename} has incorrect shape {arr.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_training_data()\n",
    "# 12/02/2018 has 406 positive dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 27,\n",
       " 29,\n",
       " 32,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 59,\n",
       " 60,\n",
       " 62,\n",
       " 65,\n",
       " 82,\n",
       " 99,\n",
       " 100,\n",
       " 114,\n",
       " 116,\n",
       " 117,\n",
       " 120,\n",
       " 121,\n",
       " 124,\n",
       " 125,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 146,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 151,\n",
       " 152,\n",
       " 153,\n",
       " 154]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the indices \n",
    "TRAIN_INDICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86, 3, 230, 230)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape of train array output\n",
    "train_shape = np.stack(train_arrays).shape\n",
    "n_train = train_shape[0]\n",
    "train_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing into one input for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  5,  6, 15, 16],\n",
       "       [ 3,  4,  7,  8, 17, 18]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How would the data after concatenation look like\n",
    "a = np.array([[1, 2], [3, 4]])\n",
    "b = np.array([[5, 6], [7, 8]])\n",
    "c = np.array([[15, 16], [17, 18]])\n",
    "\n",
    "np.concatenate((a, b, c), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the multiple (three) parallel phases as input for the LSTM model \n",
    "# Doc: https://machinelearningmastery.com/reshape-input-data-long-short-term-memory-networks-keras/\n",
    "# For example, TRAIN_INDICES has train indices for each phase; train_arrays has values in each phase. \n",
    "# To merge them into LSTM's input, do the following steps:\n",
    "# 1. define these data as a matrix of 3 columns (phases) with n rows \n",
    "# 2. data = data.reshape(1, n, 3)\n",
    "# 3. Check the shape by print(data.shape)\n",
    "\n",
    "lstm_input = np.zeros((172, 3, 690, 230))\n",
    "\n",
    "phase1_full_path = data_path + 'phase1/pos/'\n",
    "phase2_full_path = data_path + 'phase2/pos/'\n",
    "phase3_full_path = data_path + 'phase3/pos/'\n",
    "\n",
    "def create_lstm_training_input(): \n",
    "    phase1_pos_files = sorted(os.listdir(phase1_full_path))\n",
    "    phase2_pos_files = sorted(os.listdir(phase2_full_path))\n",
    "    phase3_pos_files = sorted(os.listdir(phase3_full_path))\n",
    "    \n",
    "    i = 0 \n",
    "    for index in TRAIN_INDICES: \n",
    "        phase1_arr = np.load(phase1_full_path + phase1_pos_files[index])\n",
    "        phase2_arr = np.load(phase2_full_path + phase2_pos_files[index])\n",
    "        phase3_arr = np.load(phase3_full_path +phase3_pos_files[index])\n",
    "\n",
    "        # TODO: check if the resize array is good \n",
    "        re_phase1_arr = np.resize(phase1_arr, (3, 230, 230))\n",
    "        re_phase2_arr = np.resize(phase2_arr, (3, 230, 230))\n",
    "        re_phase3_arr = np.resize(phase3_arr, (3, 230, 230))\n",
    "\n",
    "        lstm_input[i] = np.concatenate((re_phase1_arr, re_phase2_arr, re_phase3_arr), axis=1)\n",
    "        i += 1 \n",
    "   \n",
    "    # reshape to (1, ... )\n",
    "    lstm_training_input = lstm_input.reshape(1, n_train, 3) \n",
    "    \n",
    "    return lstm_training_input\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 230, 230)\n",
      "(3, 197, 174)\n",
      "(3, 199, 174)\n",
      "(3, 230, 230)\n",
      "(3, 221, 178)\n",
      "(3, 222, 174)\n",
      "(3, 230, 230)\n",
      "(3, 211, 174)\n",
      "(3, 209, 174)\n",
      "(3, 230, 230)\n",
      "(3, 207, 160)\n",
      "(3, 207, 160)\n",
      "(3, 230, 230)\n",
      "(3, 176, 174)\n",
      "(3, 176, 162)\n",
      "(3, 230, 230)\n",
      "(3, 229, 203)\n",
      "(3, 225, 203)\n",
      "(3, 230, 230)\n",
      "(3, 197, 182)\n",
      "(3, 197, 180)\n",
      "(3, 230, 230)\n",
      "(3, 203, 160)\n",
      "(3, 203, 172)\n",
      "(3, 230, 230)\n",
      "(3, 223, 188)\n",
      "(3, 224, 187)\n",
      "(3, 230, 230)\n",
      "(3, 217, 178)\n",
      "(3, 211, 176)\n",
      "(3, 230, 230)\n",
      "(3, 186, 158)\n",
      "(3, 184, 160)\n",
      "(3, 230, 230)\n",
      "(3, 203, 180)\n",
      "(3, 203, 182)\n",
      "(3, 230, 230)\n",
      "(3, 201, 160)\n",
      "(3, 205, 156)\n",
      "(3, 230, 230)\n",
      "(3, 199, 168)\n",
      "(3, 193, 168)\n",
      "(3, 230, 230)\n",
      "(3, 213, 183)\n",
      "(3, 226, 195)\n",
      "(3, 230, 230)\n",
      "(3, 205, 166)\n",
      "(3, 205, 168)\n",
      "(3, 230, 230)\n",
      "(3, 205, 164)\n",
      "(3, 205, 164)\n",
      "(3, 230, 230)\n",
      "(3, 224, 193)\n",
      "(3, 225, 193)\n",
      "(3, 230, 230)\n",
      "(3, 220, 176)\n",
      "(3, 222, 176)\n",
      "(3, 230, 230)\n",
      "(3, 216, 211)\n",
      "(3, 206, 201)\n",
      "(3, 230, 230)\n",
      "(3, 199, 168)\n",
      "(3, 201, 170)\n",
      "(3, 230, 230)\n",
      "(3, 199, 168)\n",
      "(3, 201, 170)\n",
      "(3, 230, 230)\n",
      "(3, 221, 189)\n",
      "(3, 221, 187)\n",
      "(3, 230, 230)\n",
      "(3, 229, 185)\n",
      "(3, 229, 188)\n",
      "(3, 230, 230)\n",
      "(3, 205, 164)\n",
      "(3, 207, 166)\n",
      "(3, 230, 230)\n",
      "(3, 211, 168)\n",
      "(3, 213, 166)\n",
      "(3, 230, 230)\n",
      "(3, 258, 192)\n",
      "(3, 261, 183)\n",
      "(3, 230, 230)\n",
      "(3, 262, 162)\n",
      "(3, 264, 164)\n",
      "(3, 230, 230)\n",
      "(3, 236, 194)\n",
      "(3, 221, 162)\n",
      "(3, 230, 230)\n",
      "(3, 195, 164)\n",
      "(3, 195, 166)\n",
      "(3, 230, 230)\n",
      "(3, 203, 181)\n",
      "(3, 205, 181)\n",
      "(3, 230, 230)\n",
      "(3, 215, 201)\n",
      "(3, 215, 203)\n",
      "(3, 230, 230)\n",
      "(3, 273, 170)\n",
      "(3, 260, 176)\n",
      "(3, 230, 230)\n",
      "(3, 260, 203)\n",
      "(3, 260, 205)\n",
      "(3, 230, 230)\n",
      "(3, 181, 148)\n",
      "(3, 181, 148)\n",
      "(3, 230, 230)\n",
      "(3, 234, 183)\n",
      "(3, 235, 184)\n",
      "(3, 230, 230)\n",
      "(3, 213, 193)\n",
      "(3, 209, 190)\n",
      "(3, 230, 230)\n",
      "(3, 217, 168)\n",
      "(3, 217, 168)\n",
      "(3, 230, 230)\n",
      "(3, 201, 195)\n",
      "(3, 201, 199)\n",
      "(3, 230, 230)\n",
      "(3, 201, 178)\n",
      "(3, 201, 179)\n",
      "(3, 230, 230)\n",
      "(3, 200, 154)\n",
      "(3, 199, 150)\n",
      "(3, 230, 230)\n",
      "(3, 203, 172)\n",
      "(3, 195, 176)\n",
      "(3, 230, 230)\n",
      "(3, 217, 185)\n",
      "(3, 215, 185)\n",
      "(3, 230, 230)\n",
      "(3, 213, 187)\n",
      "(3, 217, 192)\n",
      "(3, 230, 230)\n",
      "(3, 199, 178)\n",
      "(3, 201, 180)\n",
      "(3, 230, 230)\n",
      "(3, 213, 185)\n",
      "(3, 209, 187)\n",
      "(3, 230, 230)\n",
      "(3, 211, 187)\n",
      "(3, 211, 185)\n",
      "(3, 230, 230)\n",
      "(3, 238, 207)\n",
      "(3, 241, 207)\n",
      "(3, 230, 230)\n",
      "(3, 272, 195)\n",
      "(3, 216, 196)\n",
      "(3, 230, 230)\n",
      "(3, 196, 162)\n",
      "(3, 196, 162)\n",
      "(3, 230, 230)\n",
      "(3, 236, 186)\n",
      "(3, 239, 185)\n",
      "(3, 230, 230)\n",
      "(3, 205, 156)\n",
      "(3, 207, 158)\n",
      "(3, 230, 230)\n",
      "(3, 215, 180)\n",
      "(3, 215, 180)\n",
      "(3, 230, 230)\n",
      "(3, 197, 180)\n",
      "(3, 199, 183)\n",
      "(3, 230, 230)\n",
      "(3, 240, 190)\n",
      "(3, 240, 188)\n",
      "(3, 230, 230)\n",
      "(3, 193, 176)\n",
      "(3, 192, 174)\n",
      "(3, 230, 230)\n",
      "(3, 288, 244)\n",
      "(3, 283, 212)\n",
      "(3, 230, 230)\n",
      "(3, 203, 170)\n",
      "(3, 207, 170)\n",
      "(3, 230, 230)\n",
      "(3, 211, 168)\n",
      "(3, 213, 170)\n",
      "(3, 230, 230)\n",
      "(3, 263, 187)\n",
      "(3, 217, 176)\n",
      "(3, 230, 230)\n",
      "(3, 211, 176)\n",
      "(3, 209, 176)\n",
      "(3, 230, 230)\n",
      "(3, 221, 174)\n",
      "(3, 221, 176)\n",
      "(3, 230, 230)\n",
      "(3, 195, 178)\n",
      "(3, 197, 178)\n",
      "(3, 230, 230)\n",
      "(3, 207, 168)\n",
      "(3, 207, 168)\n",
      "(3, 230, 230)\n",
      "(3, 304, 201)\n",
      "(3, 301, 201)\n",
      "(3, 230, 230)\n",
      "(3, 217, 172)\n",
      "(3, 219, 172)\n",
      "(3, 230, 230)\n",
      "(3, 199, 176)\n",
      "(3, 201, 176)\n",
      "(3, 230, 230)\n",
      "(3, 231, 193)\n",
      "(3, 233, 199)\n",
      "(3, 230, 230)\n",
      "(3, 222, 199)\n",
      "(3, 223, 196)\n",
      "(3, 230, 230)\n",
      "(3, 264, 187)\n",
      "(3, 272, 188)\n",
      "(3, 230, 230)\n",
      "(3, 204, 195)\n",
      "(3, 214, 189)\n",
      "(3, 230, 230)\n",
      "(3, 246, 178)\n",
      "(3, 240, 174)\n",
      "(3, 230, 230)\n",
      "(3, 218, 172)\n",
      "(3, 217, 172)\n",
      "(3, 230, 230)\n",
      "(3, 264, 192)\n",
      "(3, 266, 192)\n",
      "(3, 230, 230)\n",
      "(3, 217, 177)\n",
      "(3, 217, 246)\n",
      "(3, 230, 230)\n",
      "(3, 237, 176)\n",
      "(3, 242, 176)\n",
      "(3, 230, 230)\n",
      "(3, 233, 194)\n",
      "(3, 237, 196)\n",
      "(3, 230, 230)\n",
      "(3, 207, 174)\n",
      "(3, 207, 174)\n",
      "(3, 230, 230)\n",
      "(3, 215, 180)\n",
      "(3, 217, 180)\n",
      "(3, 230, 230)\n",
      "(3, 203, 162)\n",
      "(3, 199, 166)\n",
      "(3, 230, 230)\n",
      "(3, 222, 188)\n",
      "(3, 226, 191)\n",
      "(3, 230, 230)\n",
      "(3, 222, 186)\n",
      "(3, 222, 186)\n",
      "(3, 230, 230)\n",
      "(3, 205, 178)\n",
      "(3, 205, 179)\n",
      "(3, 230, 230)\n",
      "(3, 199, 168)\n",
      "(3, 199, 168)\n",
      "(3, 230, 230)\n",
      "(3, 217, 174)\n",
      "(3, 215, 176)\n",
      "(3, 230, 230)\n",
      "(3, 215, 179)\n",
      "(3, 229, 182)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 81889200 into shape (1,86,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-47624f2463d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlstm_training_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_lstm_training_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-22b5232493ef>\u001b[0m in \u001b[0;36mcreate_lstm_training_input\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# reshape to (1, ... )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mlstm_training_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlstm_training_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 81889200 into shape (1,86,3)"
     ]
    }
   ],
   "source": [
    "lstm_training_input = create_lstm_training_input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"/usr/local/lib/python3.6/imp.py\", line 243, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/usr/local/lib/python3.6/imp.py\", line 343, in load_dynamic\n    return _load(spec)\nImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_mod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0m_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_pywrap_tensorflow_internal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/imp.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(name, file, filename, details)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPKG_DIRECTORY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/imp.py\u001b[0m in \u001b[0;36mload_dynamic\u001b[0;34m(name, path, file)\u001b[0m\n\u001b[1;32m    342\u001b[0m             name=name, loader=loader, origin=path)\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: libcublas.so.9.0: cannot open shared object file: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e9dd1ba6bf4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurrent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Globally-importable utils.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/utils/conv_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/backend/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tensorflow'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;31m# Try and load external backend.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmoving_averages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m  \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcomponent_api_helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msome\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mreasons\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msolutions\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mInclude\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mentire\u001b[0m \u001b[0mstack\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m above this error message when asking for help.\"\"\" % traceback.format_exc()\n\u001b[0;32m---> 74\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"/usr/local/lib/python3.6/imp.py\", line 243, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/usr/local/lib/python3.6/imp.py\", line 343, in load_dynamic\n    return _load(spec)\nImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, BatchNormalization, Dense, Flatten, Embedding\n",
    "from keras.layers.recurrent import RNN, LSTM \n",
    "from keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-bb26609819c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(n_train, 3)))\n",
    "model.add(Dense(1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
