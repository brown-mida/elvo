{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harold_triedman/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import ml.generators.mip_generator as generator\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainGen = generator.MipGenerator\n",
    "ValGen = generator.MipGenerator\n",
    "train_gen = TrainGen(dims=(220, 220, 3),\n",
    "                          batch_size=16,\n",
    "                          augment_data=True,\n",
    "                          extend_dims=False,\n",
    "                          validation=False)\n",
    "val_gen = ValGen(dims=(220, 220, 3),\n",
    "                          batch_size=16,\n",
    "                          augment_data=True,\n",
    "                          extend_dims=False,\n",
    "                          validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_last_layer(base_model, nb_classes):\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(2048, activation='relu')(x)\n",
    "    predictions = Dense(nb_classes, activation='sigmoid')(x)\n",
    "    model = Model(input=base_model.input, output=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 220, 220, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 220, 220, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 220, 220, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 110, 110, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 110, 110, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 110, 110, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 55, 55, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 55, 55, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 55, 55, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 55, 55, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 27, 27, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 27, 27, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 27, 27, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 27, 27, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 13, 13, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 13, 13, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 13, 13, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 13, 13, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              1050624   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 15,767,361\n",
      "Trainable params: 1,052,673\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harold_triedman/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(220, 220, 3))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "finished_model = add_new_last_layer(base_model, 1)\n",
    "finished_model.compile(optimizer=adam(lr=0.0001),\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "finished_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1/20\n",
      "Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "1\n",
      " 1/87 [..............................] - ETA: 8:25 - loss: 0.7028 - acc: 0.4375Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "2\n",
      " 2/87 [..............................] - ETA: 5:57 - loss: 0.6924 - acc: 0.5312Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "3\n",
      " 3/87 [>.............................] - ETA: 5:57 - loss: 0.6955 - acc: 0.4375Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "4\n",
      " 4/87 [>.............................] - ETA: 5:48 - loss: 0.7008 - acc: 0.3906Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "5\n",
      " 5/87 [>.............................] - ETA: 5:44 - loss: 0.6991 - acc: 0.4250Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "6\n",
      " 6/87 [=>............................] - ETA: 5:44 - loss: 0.6993 - acc: 0.4271Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "7\n",
      " 7/87 [=>............................] - ETA: 5:35 - loss: 0.6963 - acc: 0.4732Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "8\n",
      " 8/87 [=>............................] - ETA: 5:30 - loss: 0.6961 - acc: 0.4844Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "9\n",
      " 9/87 [==>...........................] - ETA: 5:22 - loss: 0.6981 - acc: 0.4861Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "10\n",
      "10/87 [==>...........................] - ETA: 5:17 - loss: 0.7031 - acc: 0.4813Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "11\n",
      "11/87 [==>...........................] - ETA: 5:12 - loss: 0.7047 - acc: 0.4830Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "12\n",
      "12/87 [===>..........................] - ETA: 5:09 - loss: 0.7028 - acc: 0.4896"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harold_triedman/anaconda3/lib/python3.6/site-packages/scipy/ndimage/interpolation.py:583: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.\n",
      "  \"the returned array has changed.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "13\n",
      "13/87 [===>..........................] - ETA: 5:02 - loss: 0.7020 - acc: 0.4952Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "14\n",
      "14/87 [===>..........................] - ETA: 4:57 - loss: 0.6928 - acc: 0.5179Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "15\n",
      "15/87 [====>.........................] - ETA: 4:53 - loss: 0.6932 - acc: 0.5208Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "16\n",
      "16/87 [====>.........................] - ETA: 4:49 - loss: 0.6922 - acc: 0.5234Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "17\n",
      "17/87 [====>.........................] - ETA: 4:44 - loss: 0.6863 - acc: 0.5368Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "18\n",
      "18/87 [=====>........................] - ETA: 4:40 - loss: 0.6811 - acc: 0.5486Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "19\n",
      "19/87 [=====>........................] - ETA: 4:34 - loss: 0.6774 - acc: 0.5559Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "20\n",
      "20/87 [=====>........................] - ETA: 4:29 - loss: 0.6751 - acc: 0.5594Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "21\n",
      "21/87 [======>.......................] - ETA: 4:25 - loss: 0.6688 - acc: 0.5714Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "22\n",
      "22/87 [======>.......................] - ETA: 4:22 - loss: 0.6752 - acc: 0.5625Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "23\n",
      "23/87 [======>.......................] - ETA: 4:17 - loss: 0.6759 - acc: 0.5625Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "24\n",
      "24/87 [=======>......................] - ETA: 4:13 - loss: 0.6812 - acc: 0.5547Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "25\n",
      "25/87 [=======>......................] - ETA: 4:08 - loss: 0.6825 - acc: 0.5525Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "26\n",
      "26/87 [=======>......................] - ETA: 4:04 - loss: 0.6823 - acc: 0.5529Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "27\n",
      "27/87 [========>.....................] - ETA: 3:59 - loss: 0.6824 - acc: 0.5532Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "28\n",
      "28/87 [========>.....................] - ETA: 3:55 - loss: 0.6821 - acc: 0.5513Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "29\n",
      "29/87 [=========>....................] - ETA: 3:50 - loss: 0.6831 - acc: 0.5474Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "30\n",
      "30/87 [=========>....................] - ETA: 3:46 - loss: 0.6821 - acc: 0.5500Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "31\n",
      "31/87 [=========>....................] - ETA: 3:42 - loss: 0.6819 - acc: 0.5504Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "32\n",
      "32/87 [==========>...................] - ETA: 3:37 - loss: 0.6815 - acc: 0.5566Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "33\n",
      "33/87 [==========>...................] - ETA: 3:33 - loss: 0.6825 - acc: 0.5511Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "34\n",
      "34/87 [==========>...................] - ETA: 3:28 - loss: 0.6816 - acc: 0.5570Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "35\n",
      "35/87 [===========>..................] - ETA: 3:24 - loss: 0.6814 - acc: 0.5607Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "36\n",
      "36/87 [===========>..................] - ETA: 3:20 - loss: 0.6819 - acc: 0.5590Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "37\n",
      "37/87 [===========>..................] - ETA: 3:16 - loss: 0.6818 - acc: 0.5574Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "38\n",
      "38/87 [============>.................] - ETA: 3:12 - loss: 0.6817 - acc: 0.5576Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "39\n",
      "39/87 [============>.................] - ETA: 3:08 - loss: 0.6818 - acc: 0.5529Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "40\n",
      "40/87 [============>.................] - ETA: 3:05 - loss: 0.6822 - acc: 0.5516Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "41\n",
      "41/87 [=============>................] - ETA: 3:01 - loss: 0.6814 - acc: 0.5549Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "42\n",
      "42/87 [=============>................] - ETA: 2:56 - loss: 0.6803 - acc: 0.5610Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "43\n",
      "43/87 [=============>................] - ETA: 2:52 - loss: 0.6805 - acc: 0.5581Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "44\n",
      "44/87 [==============>...............] - ETA: 2:48 - loss: 0.6796 - acc: 0.5611Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "45\n",
      "45/87 [==============>...............] - ETA: 2:44 - loss: 0.6793 - acc: 0.5611Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "46\n",
      "46/87 [==============>...............] - ETA: 2:41 - loss: 0.6778 - acc: 0.5639Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "47\n",
      "47/87 [===============>..............] - ETA: 2:36 - loss: 0.6778 - acc: 0.5625Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "48\n",
      "48/87 [===============>..............] - ETA: 2:32 - loss: 0.6797 - acc: 0.5586Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "49\n",
      "49/87 [===============>..............] - ETA: 2:28 - loss: 0.6786 - acc: 0.5612Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "50\n",
      "50/87 [================>.............] - ETA: 2:24 - loss: 0.6808 - acc: 0.5575Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "51\n",
      "51/87 [================>.............] - ETA: 2:20 - loss: 0.6794 - acc: 0.5600Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "52\n",
      "52/87 [================>.............] - ETA: 2:16 - loss: 0.6793 - acc: 0.5613Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "53\n",
      "53/87 [=================>............] - ETA: 2:12 - loss: 0.6781 - acc: 0.5637Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "54\n",
      "54/87 [=================>............] - ETA: 2:08 - loss: 0.6788 - acc: 0.5637Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "55\n",
      "55/87 [=================>............] - ETA: 2:04 - loss: 0.6794 - acc: 0.5636Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "56\n",
      "56/87 [==================>...........] - ETA: 2:00 - loss: 0.6781 - acc: 0.5636Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "57\n",
      "57/87 [==================>...........] - ETA: 1:56 - loss: 0.6773 - acc: 0.5669Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "58\n",
      "58/87 [===================>..........] - ETA: 1:52 - loss: 0.6761 - acc: 0.5700Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "59\n",
      "59/87 [===================>..........] - ETA: 1:48 - loss: 0.6760 - acc: 0.5699Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "60\n",
      "60/87 [===================>..........] - ETA: 1:45 - loss: 0.6751 - acc: 0.5698Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "61\n",
      "61/87 [====================>.........] - ETA: 1:41 - loss: 0.6765 - acc: 0.5666Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "62\n",
      "62/87 [====================>.........] - ETA: 1:37 - loss: 0.6770 - acc: 0.5645Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "63\n",
      "63/87 [====================>.........] - ETA: 1:33 - loss: 0.6756 - acc: 0.5665Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "64\n",
      "64/87 [=====================>........] - ETA: 1:29 - loss: 0.6741 - acc: 0.5693Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "65\n",
      "65/87 [=====================>........] - ETA: 1:25 - loss: 0.6733 - acc: 0.5712Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "66\n",
      "66/87 [=====================>........] - ETA: 1:21 - loss: 0.6720 - acc: 0.5748Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "67\n",
      "67/87 [======================>.......] - ETA: 1:17 - loss: 0.6708 - acc: 0.5784Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "68\n",
      "68/87 [======================>.......] - ETA: 1:13 - loss: 0.6711 - acc: 0.5781Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "69\n",
      "69/87 [======================>.......] - ETA: 1:09 - loss: 0.6720 - acc: 0.5752Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "70\n",
      "70/87 [=======================>......] - ETA: 1:05 - loss: 0.6713 - acc: 0.5759Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "71\n",
      "71/87 [=======================>......] - ETA: 1:01 - loss: 0.6701 - acc: 0.5801Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "72\n",
      "72/87 [=======================>......] - ETA: 57s - loss: 0.6698 - acc: 0.5807 Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "73\n",
      "73/87 [========================>.....] - ETA: 54s - loss: 0.6692 - acc: 0.5830Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "74\n",
      "74/87 [========================>.....] - ETA: 50s - loss: 0.6682 - acc: 0.5836Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "75\n",
      "75/87 [========================>.....] - ETA: 46s - loss: 0.6674 - acc: 0.5833Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "76\n",
      "76/87 [=========================>....] - ETA: 42s - loss: 0.6664 - acc: 0.5847Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "77\n",
      "77/87 [=========================>....] - ETA: 38s - loss: 0.6654 - acc: 0.5860Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "78\n",
      "78/87 [=========================>....] - ETA: 34s - loss: 0.6670 - acc: 0.5833Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "79\n",
      "79/87 [==========================>...] - ETA: 30s - loss: 0.6685 - acc: 0.5799Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "80\n",
      "80/87 [==========================>...] - ETA: 26s - loss: 0.6675 - acc: 0.5805Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "81\n",
      "81/87 [==========================>...] - ETA: 23s - loss: 0.6658 - acc: 0.5826Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "82\n",
      "82/87 [===========================>..] - ETA: 19s - loss: 0.6645 - acc: 0.5846Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "83\n",
      "83/87 [===========================>..] - ETA: 15s - loss: 0.6637 - acc: 0.5858Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "84\n",
      "84/87 [===========================>..] - ETA: 11s - loss: 0.6637 - acc: 0.5863Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "85\n",
      "85/87 [============================>.] - ETA: 7s - loss: 0.6633 - acc: 0.5860 Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "86\n",
      "86/87 [============================>.] - ETA: 3s - loss: 0.6623 - acc: 0.5872Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "0\n",
      "0\n",
      "Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "1\n",
      "Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "2\n",
      "Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "3\n",
      "Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "4\n",
      "Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "5\n",
      "Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "6\n",
      "Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "7\n",
      "Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "8\n",
      "Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "9\n",
      "Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "0\n",
      "Loaded entire batch.\n",
      "\b(16, 220, 220, 3)\n",
      "87/87 [==============================] - 375s 4s/step - loss: 0.6613 - acc: 0.5884 - val_loss: 0.6121 - val_acc: 0.6438\n",
      "\n",
      "Epoch 00001: saving model to tmp/vgg16_pretrained_weights.hdf5\n",
      "Epoch 2/20\n",
      "1\n",
      " 1/87 [..............................] - ETA: 4s - loss: 0.6187 - acc: 0.7500Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "2\n",
      " 2/87 [..............................] - ETA: 2:35 - loss: 0.6367 - acc: 0.7188Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "3\n",
      " 3/87 [>.............................] - ETA: 3:58 - loss: 0.6733 - acc: 0.6250Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "4\n",
      " 4/87 [>.............................] - ETA: 4:07 - loss: 0.6483 - acc: 0.6562Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "5\n",
      " 5/87 [>.............................] - ETA: 4:12 - loss: 0.6730 - acc: 0.5875Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "6\n",
      " 6/87 [=>............................] - ETA: 4:23 - loss: 0.6648 - acc: 0.5938Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "7\n",
      " 7/87 [=>............................] - ETA: 4:25 - loss: 0.6494 - acc: 0.6250Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "8\n",
      " 8/87 [=>............................] - ETA: 4:25 - loss: 0.6494 - acc: 0.6172Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "9\n",
      " 9/87 [==>...........................] - ETA: 4:25 - loss: 0.6455 - acc: 0.6250Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "10\n",
      "10/87 [==>...........................] - ETA: 4:23 - loss: 0.6457 - acc: 0.6125Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "11\n",
      "11/87 [==>...........................] - ETA: 4:21 - loss: 0.6446 - acc: 0.6023Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "12\n",
      "12/87 [===>..........................] - ETA: 4:23 - loss: 0.6403 - acc: 0.6146Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "13\n",
      "13/87 [===>..........................] - ETA: 4:21 - loss: 0.6332 - acc: 0.6250Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "14\n",
      "14/87 [===>..........................] - ETA: 4:17 - loss: 0.6308 - acc: 0.6295Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "15\n",
      "15/87 [====>.........................] - ETA: 4:16 - loss: 0.6349 - acc: 0.6250Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "16\n",
      "16/87 [====>.........................] - ETA: 4:12 - loss: 0.6303 - acc: 0.6328Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "17\n",
      "17/87 [====>.........................] - ETA: 4:08 - loss: 0.6296 - acc: 0.6324Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "18\n",
      "18/87 [=====>........................] - ETA: 4:05 - loss: 0.6240 - acc: 0.6424Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "19\n",
      "19/87 [=====>........................] - ETA: 4:01 - loss: 0.6244 - acc: 0.6447Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "20\n",
      "20/87 [=====>........................] - ETA: 3:57 - loss: 0.6234 - acc: 0.6500Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "21\n",
      "21/87 [======>.......................] - ETA: 3:53 - loss: 0.6176 - acc: 0.6577Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "22\n",
      "22/87 [======>.......................] - ETA: 3:51 - loss: 0.6203 - acc: 0.6449Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "23\n",
      "23/87 [======>.......................] - ETA: 3:48 - loss: 0.6204 - acc: 0.6413Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "24\n",
      "24/87 [=======>......................] - ETA: 3:44 - loss: 0.6252 - acc: 0.6302Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "25\n",
      "25/87 [=======>......................] - ETA: 3:41 - loss: 0.6273 - acc: 0.6250Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "26\n",
      "26/87 [=======>......................] - ETA: 3:37 - loss: 0.6266 - acc: 0.6226Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "27\n",
      "27/87 [========>.....................] - ETA: 3:34 - loss: 0.6263 - acc: 0.6181Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "28\n",
      "28/87 [========>.....................] - ETA: 3:31 - loss: 0.6266 - acc: 0.6161Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "29\n",
      "29/87 [=========>....................] - ETA: 3:28 - loss: 0.6296 - acc: 0.6121Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "30\n",
      "30/87 [=========>....................] - ETA: 3:24 - loss: 0.6301 - acc: 0.6125Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "31\n",
      "31/87 [=========>....................] - ETA: 3:21 - loss: 0.6326 - acc: 0.6109Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "32\n",
      "32/87 [==========>...................] - ETA: 3:17 - loss: 0.6326 - acc: 0.6152Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "33\n",
      "33/87 [==========>...................] - ETA: 3:13 - loss: 0.6345 - acc: 0.6098Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "34\n",
      "34/87 [==========>...................] - ETA: 3:10 - loss: 0.6341 - acc: 0.6158Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "35\n",
      "35/87 [===========>..................] - ETA: 3:06 - loss: 0.6331 - acc: 0.6196Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "36\n",
      "36/87 [===========>..................] - ETA: 3:04 - loss: 0.6348 - acc: 0.6181Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "37\n",
      "37/87 [===========>..................] - ETA: 3:00 - loss: 0.6350 - acc: 0.6166Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "38\n",
      "38/87 [============>.................] - ETA: 2:56 - loss: 0.6331 - acc: 0.6201Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "39\n",
      "39/87 [============>.................] - ETA: 2:53 - loss: 0.6315 - acc: 0.6234Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "40\n",
      "40/87 [============>.................] - ETA: 2:49 - loss: 0.6321 - acc: 0.6234Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "41\n",
      "41/87 [=============>................] - ETA: 2:46 - loss: 0.6309 - acc: 0.6220Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "42\n",
      "42/87 [=============>................] - ETA: 2:42 - loss: 0.6299 - acc: 0.6235Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "43\n",
      "43/87 [=============>................] - ETA: 2:38 - loss: 0.6305 - acc: 0.6206Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "44\n",
      "44/87 [==============>...............] - ETA: 2:35 - loss: 0.6306 - acc: 0.6222Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "45\n",
      "45/87 [==============>...............] - ETA: 2:31 - loss: 0.6314 - acc: 0.6222Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "46\n",
      "46/87 [==============>...............] - ETA: 2:27 - loss: 0.6297 - acc: 0.6236Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "47\n",
      "47/87 [===============>..............] - ETA: 2:24 - loss: 0.6286 - acc: 0.6237Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "48\n",
      "48/87 [===============>..............] - ETA: 2:20 - loss: 0.6325 - acc: 0.6185Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "49\n",
      "49/87 [===============>..............] - ETA: 2:16 - loss: 0.6324 - acc: 0.6199Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "50\n",
      "50/87 [================>.............] - ETA: 2:13 - loss: 0.6338 - acc: 0.6188Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "51\n",
      "51/87 [================>.............] - ETA: 2:09 - loss: 0.6335 - acc: 0.6176Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "52\n",
      "52/87 [================>.............] - ETA: 2:05 - loss: 0.6337 - acc: 0.6178Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "53\n",
      "53/87 [=================>............] - ETA: 2:02 - loss: 0.6335 - acc: 0.6203Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "54\n",
      "54/87 [=================>............] - ETA: 1:58 - loss: 0.6354 - acc: 0.6181Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "55\n",
      "55/87 [=================>............] - ETA: 1:55 - loss: 0.6371 - acc: 0.6170Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/87 [==================>...........] - ETA: 1:51 - loss: 0.6359 - acc: 0.6183Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "57\n",
      "57/87 [==================>...........] - ETA: 1:47 - loss: 0.6348 - acc: 0.6206Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "58\n",
      "58/87 [===================>..........] - ETA: 1:44 - loss: 0.6344 - acc: 0.6218Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "59\n",
      "59/87 [===================>..........] - ETA: 1:40 - loss: 0.6342 - acc: 0.6208Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "60\n",
      "60/87 [===================>..........] - ETA: 1:37 - loss: 0.6328 - acc: 0.6240Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "61\n",
      "61/87 [====================>.........] - ETA: 1:33 - loss: 0.6347 - acc: 0.6209Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "62\n",
      "62/87 [====================>.........] - ETA: 1:30 - loss: 0.6348 - acc: 0.6200Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "63\n",
      "63/87 [====================>.........] - ETA: 1:26 - loss: 0.6339 - acc: 0.6200Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "64\n",
      "64/87 [=====================>........] - ETA: 1:23 - loss: 0.6323 - acc: 0.6230Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "65\n",
      "65/87 [=====================>........] - ETA: 1:19 - loss: 0.6316 - acc: 0.6250Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "66\n",
      "66/87 [=====================>........] - ETA: 1:15 - loss: 0.6304 - acc: 0.6269Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "67\n",
      "67/87 [======================>.......] - ETA: 1:12 - loss: 0.6292 - acc: 0.6297Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "68\n",
      "68/87 [======================>.......] - ETA: 1:08 - loss: 0.6297 - acc: 0.6287Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "69\n",
      "69/87 [======================>.......] - ETA: 1:05 - loss: 0.6312 - acc: 0.6268Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "70\n",
      "70/87 [=======================>......] - ETA: 1:01 - loss: 0.6303 - acc: 0.6268Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "71\n",
      "71/87 [=======================>......] - ETA: 57s - loss: 0.6298 - acc: 0.6294 Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "72\n",
      "72/87 [=======================>......] - ETA: 54s - loss: 0.6298 - acc: 0.6285Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "73\n",
      "73/87 [========================>.....] - ETA: 50s - loss: 0.6295 - acc: 0.6293Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "74\n",
      "74/87 [========================>.....] - ETA: 47s - loss: 0.6285 - acc: 0.6318Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "75\n",
      "75/87 [========================>.....] - ETA: 43s - loss: 0.6279 - acc: 0.6325Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "76\n",
      "76/87 [=========================>....] - ETA: 39s - loss: 0.6266 - acc: 0.6349Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "77\n",
      "77/87 [=========================>....] - ETA: 36s - loss: 0.6258 - acc: 0.6364Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "78\n",
      "78/87 [=========================>....] - ETA: 32s - loss: 0.6275 - acc: 0.6330Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "79\n",
      "79/87 [==========================>...] - ETA: 28s - loss: 0.6294 - acc: 0.6305Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "80\n",
      "80/87 [==========================>...] - ETA: 25s - loss: 0.6285 - acc: 0.6305Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "81\n",
      "81/87 [==========================>...] - ETA: 21s - loss: 0.6267 - acc: 0.6319Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "82\n",
      "82/87 [===========================>..] - ETA: 18s - loss: 0.6252 - acc: 0.6341Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "83\n",
      "83/87 [===========================>..] - ETA: 14s - loss: 0.6245 - acc: 0.6333Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "84\n",
      "84/87 [===========================>..] - ETA: 10s - loss: 0.6249 - acc: 0.6317Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "85\n",
      "85/87 [============================>.] - ETA: 7s - loss: 0.6252 - acc: 0.6309 Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "86\n",
      "86/87 [============================>.] - ETA: 3s - loss: 0.6245 - acc: 0.6323Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "0\n",
      "1\n",
      "Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "2\n",
      "Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "3\n",
      "Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "4\n",
      "Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "5\n",
      "Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "6\n",
      "Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "7\n",
      "Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "8\n",
      "Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "9\n",
      "Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "0\n",
      "Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "1\n",
      "Loaded entire batch\n",
      "(16, 220, 220, 3)\n",
      "87/87 [==============================] - 356s 4s/step - loss: 0.6236 - acc: 0.6336 - val_loss: 0.6012 - val_acc: 0.6687\n",
      "\n",
      "Epoch 00002: saving model to tmp/vgg16_pretrained_weights.hdf5\n",
      "Epoch 3/20\n",
      "1\n",
      " 1/87 [..............................] - ETA: 4s - loss: 0.6004 - acc: 0.6250Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "2\n",
      " 2/87 [..............................] - ETA: 2:33 - loss: 0.5966 - acc: 0.6875Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "3\n",
      " 3/87 [>.............................] - ETA: 3:29 - loss: 0.6369 - acc: 0.6042Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "4\n",
      " 4/87 [>.............................] - ETA: 3:48 - loss: 0.6285 - acc: 0.6094Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "5\n",
      " 5/87 [>.............................] - ETA: 3:59 - loss: 0.6603 - acc: 0.5750Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "6\n",
      " 6/87 [=>............................] - ETA: 4:07 - loss: 0.6518 - acc: 0.5938Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "7\n",
      " 7/87 [=>............................] - ETA: 4:22 - loss: 0.6334 - acc: 0.6250Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "8\n",
      " 8/87 [=>............................] - ETA: 4:24 - loss: 0.6323 - acc: 0.6250Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "9\n",
      " 9/87 [==>...........................] - ETA: 4:24 - loss: 0.6285 - acc: 0.6319Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "10\n",
      "10/87 [==>...........................] - ETA: 4:24 - loss: 0.6290 - acc: 0.6125Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "11\n",
      "11/87 [==>...........................] - ETA: 4:23 - loss: 0.6230 - acc: 0.6193Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "12\n",
      "12/87 [===>..........................] - ETA: 4:20 - loss: 0.6187 - acc: 0.6302Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "13\n",
      "13/87 [===>..........................] - ETA: 4:19 - loss: 0.6101 - acc: 0.6394Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "14\n",
      "14/87 [===>..........................] - ETA: 4:15 - loss: 0.6080 - acc: 0.6429Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "15\n",
      "15/87 [====>.........................] - ETA: 4:13 - loss: 0.6134 - acc: 0.6292Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "16\n",
      "16/87 [====>.........................] - ETA: 4:09 - loss: 0.6073 - acc: 0.6406Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "17\n",
      "17/87 [====>.........................] - ETA: 4:05 - loss: 0.6036 - acc: 0.6507Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "18\n",
      "18/87 [=====>........................] - ETA: 4:02 - loss: 0.5979 - acc: 0.6597Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "19\n",
      "19/87 [=====>........................] - ETA: 4:01 - loss: 0.5999 - acc: 0.6612Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "20\n",
      "20/87 [=====>........................] - ETA: 3:58 - loss: 0.5972 - acc: 0.6687Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "21\n",
      "21/87 [======>.......................] - ETA: 3:55 - loss: 0.5905 - acc: 0.6756Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "22\n",
      "22/87 [======>.......................] - ETA: 3:53 - loss: 0.5952 - acc: 0.6619Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "23\n",
      "23/87 [======>.......................] - ETA: 3:50 - loss: 0.5954 - acc: 0.6576Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "24\n",
      "24/87 [=======>......................] - ETA: 3:46 - loss: 0.5995 - acc: 0.6510Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "25\n",
      "25/87 [=======>......................] - ETA: 3:43 - loss: 0.6018 - acc: 0.6475Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "26\n",
      "26/87 [=======>......................] - ETA: 3:40 - loss: 0.6012 - acc: 0.6466Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "27\n",
      "27/87 [========>.....................] - ETA: 3:36 - loss: 0.6029 - acc: 0.6412Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "28\n",
      "28/87 [========>.....................] - ETA: 3:33 - loss: 0.6023 - acc: 0.6429Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "29\n",
      "29/87 [=========>....................] - ETA: 3:29 - loss: 0.6053 - acc: 0.6422Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "30\n",
      "30/87 [=========>....................] - ETA: 3:26 - loss: 0.6063 - acc: 0.6438Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "31\n",
      "31/87 [=========>....................] - ETA: 3:22 - loss: 0.6104 - acc: 0.6391Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "32\n",
      "32/87 [==========>...................] - ETA: 3:18 - loss: 0.6107 - acc: 0.6367Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "33\n",
      "33/87 [==========>...................] - ETA: 3:15 - loss: 0.6137 - acc: 0.6307Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "34\n",
      "34/87 [==========>...................] - ETA: 3:12 - loss: 0.6129 - acc: 0.6360Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "35\n",
      "35/87 [===========>..................] - ETA: 3:08 - loss: 0.6114 - acc: 0.6411Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "36\n",
      "36/87 [===========>..................] - ETA: 3:04 - loss: 0.6121 - acc: 0.6406Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "37\n",
      "37/87 [===========>..................] - ETA: 3:01 - loss: 0.6114 - acc: 0.6436Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "38\n",
      "38/87 [============>.................] - ETA: 2:57 - loss: 0.6096 - acc: 0.6447Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "39\n",
      "39/87 [============>.................] - ETA: 2:54 - loss: 0.6088 - acc: 0.6474Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "40\n",
      "40/87 [============>.................] - ETA: 2:50 - loss: 0.6095 - acc: 0.6484Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "41\n",
      "41/87 [=============>................] - ETA: 2:46 - loss: 0.6089 - acc: 0.6479Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "42\n",
      "42/87 [=============>................] - ETA: 2:43 - loss: 0.6074 - acc: 0.6518Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "43\n",
      "43/87 [=============>................] - ETA: 2:39 - loss: 0.6096 - acc: 0.6483Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "44\n",
      "44/87 [==============>...............] - ETA: 2:35 - loss: 0.6100 - acc: 0.6477Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "45\n",
      "45/87 [==============>...............] - ETA: 2:32 - loss: 0.6099 - acc: 0.6486Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "46\n",
      "46/87 [==============>...............] - ETA: 2:28 - loss: 0.6080 - acc: 0.6508Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "47\n",
      "47/87 [===============>..............] - ETA: 2:25 - loss: 0.6079 - acc: 0.6503Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "48\n",
      "48/87 [===============>..............] - ETA: 2:21 - loss: 0.6112 - acc: 0.6458Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "49\n",
      "49/87 [===============>..............] - ETA: 2:17 - loss: 0.6112 - acc: 0.6467Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "50\n",
      "50/87 [================>.............] - ETA: 2:13 - loss: 0.6133 - acc: 0.6462Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "51\n",
      "51/87 [================>.............] - ETA: 2:10 - loss: 0.6124 - acc: 0.6458Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "52\n",
      "52/87 [================>.............] - ETA: 2:06 - loss: 0.6127 - acc: 0.6466Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "53\n",
      "53/87 [=================>............] - ETA: 2:03 - loss: 0.6128 - acc: 0.6474Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "54\n",
      "54/87 [=================>............] - ETA: 1:59 - loss: 0.6152 - acc: 0.6470Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "55\n",
      "55/87 [=================>............] - ETA: 1:56 - loss: 0.6181 - acc: 0.6420Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "56\n",
      "56/87 [==================>...........] - ETA: 1:52 - loss: 0.6160 - acc: 0.6440Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "57\n",
      "57/87 [==================>...........] - ETA: 1:49 - loss: 0.6157 - acc: 0.6425Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "58\n",
      "58/87 [===================>..........] - ETA: 1:45 - loss: 0.6165 - acc: 0.6422Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "59\n",
      "59/87 [===================>..........] - ETA: 1:41 - loss: 0.6164 - acc: 0.6409Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "60\n",
      "60/87 [===================>..........] - ETA: 1:38 - loss: 0.6153 - acc: 0.6406Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "61\n",
      "61/87 [====================>.........] - ETA: 1:35 - loss: 0.6170 - acc: 0.6404Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "62\n",
      "62/87 [====================>.........] - ETA: 1:31 - loss: 0.6169 - acc: 0.6411Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "63\n",
      "63/87 [====================>.........] - ETA: 1:27 - loss: 0.6163 - acc: 0.6438Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "64\n",
      "64/87 [=====================>........] - ETA: 1:24 - loss: 0.6145 - acc: 0.6465Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "65\n",
      "65/87 [=====================>........] - ETA: 1:20 - loss: 0.6135 - acc: 0.6462Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "66\n",
      "66/87 [=====================>........] - ETA: 1:16 - loss: 0.6129 - acc: 0.6468Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "67\n",
      "67/87 [======================>.......] - ETA: 1:13 - loss: 0.6113 - acc: 0.6511Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "68\n",
      "68/87 [======================>.......] - ETA: 1:09 - loss: 0.6119 - acc: 0.6498Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "69\n",
      "69/87 [======================>.......] - ETA: 1:06 - loss: 0.6138 - acc: 0.6458Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "70\n",
      "70/87 [=======================>......] - ETA: 1:02 - loss: 0.6128 - acc: 0.6473Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "71\n",
      "71/87 [=======================>......] - ETA: 58s - loss: 0.6118 - acc: 0.6496 Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "72\n",
      "72/87 [=======================>......] - ETA: 55s - loss: 0.6130 - acc: 0.6484Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "73\n",
      "73/87 [========================>.....] - ETA: 51s - loss: 0.6130 - acc: 0.6490Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "74\n",
      "74/87 [========================>.....] - ETA: 47s - loss: 0.6118 - acc: 0.6512Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "75\n",
      "75/87 [========================>.....] - ETA: 44s - loss: 0.6110 - acc: 0.6525Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "76\n",
      "76/87 [=========================>....] - ETA: 40s - loss: 0.6091 - acc: 0.6546Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "77\n",
      "77/87 [=========================>....] - ETA: 37s - loss: 0.6081 - acc: 0.6550Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "78\n",
      "78/87 [=========================>....] - ETA: 33s - loss: 0.6099 - acc: 0.6530Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "79\n",
      "79/87 [==========================>...] - ETA: 29s - loss: 0.6108 - acc: 0.6527Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "80\n",
      "80/87 [==========================>...] - ETA: 25s - loss: 0.6101 - acc: 0.6539Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "81\n",
      "81/87 [==========================>...] - ETA: 22s - loss: 0.6084 - acc: 0.6566Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "82\n",
      "82/87 [===========================>..] - ETA: 18s - loss: 0.6068 - acc: 0.6593Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "83\n",
      "83/87 [===========================>..] - ETA: 14s - loss: 0.6058 - acc: 0.6604Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "84\n",
      "84/87 [===========================>..] - ETA: 11s - loss: 0.6063 - acc: 0.6577Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "85\n",
      "85/87 [============================>.] - ETA: 7s - loss: 0.6068 - acc: 0.6566 Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "86\n",
      "86/87 [============================>.] - ETA: 3s - loss: 0.6065 - acc: 0.6577Loaded entire batch.\n",
      "(16, 220, 220, 3)\n",
      "0\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "mc_callback = ModelCheckpoint(filepath='tmp/vgg16_pretrained_weights.hdf5', verbose=1)\n",
    "finished_model.fit_generator(\n",
    "    generator=train_gen.generate(),\n",
    "    steps_per_epoch=train_gen.get_steps_per_epoch(),\n",
    "    validation_data=val_gen.generate(),\n",
    "    validation_steps=val_gen.get_steps_per_epoch(),\n",
    "    epochs=20,\n",
    "    callbacks=[mc_callback],\n",
    "    verbose=1,\n",
    "    max_queue_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
